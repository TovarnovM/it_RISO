{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2  # pip install opencv-python\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Скачать датасет с картинками собак и кошек](https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBUILD_DATA = False # set to true to one once, the notebook back to false unless you want to change something in your training data.\n",
    "\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"d:/PetImages/Cat\"\n",
    "    DOGS = \"d:/PetImages/Dog\"\n",
    "    TESTING = \"PetImages/Testing\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "    \n",
    "    def convert_img(self, fname):\n",
    "        img = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "        return np.array(img)\n",
    "    \n",
    "    def all_pics_paths(self):\n",
    "        res = []\n",
    "        for label in self.LABELS:\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "#                         converted_img = self.convert_img(path)\n",
    "                        res.append((path,self.LABELS[label]))\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "        np.random.shuffle(res)\n",
    "        return res\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "                        m = self.convert_img(path)\n",
    "                        self.training_data.append([m, np.eye(2)[self.LABELS[label]]]) \n",
    "                        #print(np.eye(2)[self.LABELS[label]])\n",
    "\n",
    "                        if label == self.CATS:\n",
    "                            self.catcount += 1\n",
    "                        elif label == self.DOGS:\n",
    "                            self.dogcount += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(label, f, str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print('Cats:',dogsvcats.catcount)\n",
    "        print('Dogs:',dogsvcats.dogcount)\n",
    "        \n",
    "    def load_training_data(self):\n",
    "        self.training_data = np.load(\"training_data.npy\",allow_pickle=True)\n",
    "        self.catcount = 0\n",
    "        self.dogcount = 0\n",
    "        for m, label in self.training_data:\n",
    "            if label[0] == 1:\n",
    "                self.catcount += 1\n",
    "            if label[1] == 1:\n",
    "                self.dogcount +=1\n",
    "        print('Cats:',dogsvcats.catcount)\n",
    "        print('Dogs:',dogsvcats.dogcount)\n",
    "        \n",
    "    \n",
    "        \n",
    "dogsvcats = DogsVSCats()\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats.make_training_data()\n",
    "else:\n",
    "    dogsvcats.load_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "all_pics = dogsvcats.all_pics_paths()\n",
    "\n",
    "@interact(i=IntSlider(min=0, max=len(all_pics)-1, step=1, value=0))\n",
    "def print_some(i): \n",
    "    fpath, label = all_pics[i]\n",
    "    img = cv2.imread(fpath)\n",
    "    converted_img = dogsvcats.convert_img(fpath)\n",
    "    who = 'ПЁсель' if label else 'КОтель'\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img[:,:,::-1])\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(converted_img, cmap='gray')\n",
    "    plt.title(f'На картинке {who}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 conv\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        \n",
    "        x = T.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "        \n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "training_data = dogsvcats.training_data\n",
    "X = T.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "X = X/255.0\n",
    "y = T.Tensor([i[1] for i in training_data])\n",
    "\n",
    "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "\n",
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "            #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "            net.zero_grad()\n",
    "\n",
    "            outputs = net(batch_X)\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()    # Does the update\n",
    "\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "        \n",
    "def test(net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with T.no_grad():\n",
    "        for i in tqdm(range(len(test_X))):\n",
    "            real_class = torch.argmax(test_y[i])\n",
    "            net_out = net(test_X[i].view(-1, 1, 50, 50))[0]  # returns a list, \n",
    "            predicted_class = T.argmax(net_out)\n",
    "\n",
    "            if predicted_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if T.cuda.is_available():\n",
    "    device = T.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = T.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netg = Net().to(device)\n",
    "train_Xg = train_X.to(device)\n",
    "train_yg = train_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, ep):\n",
    "    BATCH_SIZE = 100\n",
    "    EPOCHS = ep\n",
    "    optimizer = optim.Adam(netg.parameters(), lr=0.001)\n",
    "    loss_function = nn.MSELoss()\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "            batch_X = train_Xg[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
    "            batch_y = train_yg[i:i+BATCH_SIZE]\n",
    "\n",
    "            batch_X, batch_y = batch_X, batch_y\n",
    "\n",
    "            netg.zero_grad()\n",
    "            outputs = netg(batch_X)\n",
    "\n",
    "            matches  = [T.argmax(i)==T.argmax(j) for i, j in zip(outputs, batch_y)]\n",
    "            in_sample_acc = matches.count(True)/len(matches)\n",
    "\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(loss)\n",
    "        print(\"In-sample acc:\",round(in_sample_acc, 2))\n",
    "        \n",
    "train(netg, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_test(net):\n",
    "    BATCH_SIZE = len(test_y)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with T.no_grad():\n",
    "        #np.random.shuffle(test_X)\n",
    "        #np.random.shuffle(test_y)\n",
    "\n",
    "        batch_X = test_X[:BATCH_SIZE].view(-1,1,50,50)\n",
    "        batch_y = test_y[:BATCH_SIZE]\n",
    "\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        net.zero_grad()\n",
    "        outputs = netg(batch_X)\n",
    "\n",
    "        matches, notmatches  = [], []\n",
    "        for i, (o, b) in enumerate(zip(outputs, batch_y)):\n",
    "            if T.argmax(o)!=T.argmax(b):\n",
    "                notmatches.append(test_X[i])\n",
    "            else:\n",
    "                matches.append(test_X[i])\n",
    "        acc = 1-len(notmatches)/BATCH_SIZE\n",
    "\n",
    "        print(\"Test Accuracy:\", round(acc, 3))\n",
    "        return matches, notmatches\n",
    "\n",
    "rights, wrongs = batch_test(netg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(i=IntSlider(min=0, max=len(wrongs)-1, step=1, value=0))\n",
    "def plot_wrongs(i):\n",
    "    label=T.argmax(netg(wrongs[i].view(-1,1,50,50).to(device)))\n",
    "    plt.imshow(wrongs[i], cmap='gray')\n",
    "    who = 'ПЁсель' if label else 'КОтель'\n",
    "    plt.title(f'Моя сеть считает, что это {who}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(i=IntSlider(min=0, max=len(rights)-1, step=1, value=0))\n",
    "def plot_wrongs(i):\n",
    "    label=T.argmax(netg(rights[i].view(-1,1,50,50).to(device)))\n",
    "    plt.imshow(rights[i], cmap='gray')\n",
    "    who = 'ПЁсель' if label else 'КОтель'\n",
    "    plt.title(f'Моя сеть считает, что это {who}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
